<section class="bg-faded small-padding" id="About">
    <div class="container no-gutter">
        <div class="row no-gutter">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">About Us</h2>
                <hr class="primary">
            </div>
        </div>
    </div>

    <div class="container">
        <div class="row">
            <div class="col-sm-6">                
                <iframe width="556" height="312" src="https://www.youtube.com/embed/HVlJCkRwTT4?si=JgEDU2e_hni3KHnw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>

            <div class="col-sm-6">
                <p></p>
                <p class='text-justify'>Welcome to <strong><em>Sound and Music Computing Lab</em></strong> at National University of Singapore! The NUS Sound and Music Computing Lab strives to develop Sound and Music Computing (SMC) technologies, in particular Music Information Retrieval (MIR) technologies, with an emphasis on applications in e-Learning (especially computer-assisted music and language edutainment) and e-Health (especially computer-assisted music-enhanced exercise and therapy). </p>
                
                    
                <p class='text-justify' style="text-indent: 20px">We seek to harness the synergy of SMC, MIR, mobile computing, and cloud computing technologies to promote healthy lifestyles and to facilitate disease prevention, diagnosis, and treatment in both developed countries and resource-poor developing countries.</p>
            </div>
        </div>

        <div class="row">
            <p></p>
        </div>


        <div class="row">
            <h3 id="-recent-news"><i class="fa fa-fw fa-rss "></i> Recent News</h3>
        </div>
        <div style="background-color:#f7d5bc42;">
            <ul style="width: auto; height: 215px; overflow: auto; line-height: 2;">
                <p></p>

                <li><div class="indent2"><b>[2025.05]</b> New paper <em><a href="archive/pdf/2025/2025_LivePoem (IJCAI25 HAI).pdf" target="_blank">LivePoem: Improving the Learning Experience of Classical Chinese Poetry with AI-Generated Musical Storyboards</a></em> is accepted by IJCAI 2025. Congrats to Qihao, Stan, and Torin!</div></li>

                <li><div class="indent2"><b>[2025.05]</b> New paper <em><a href="archive/pdf/2025/2025_Interspeech_464.pdf" target="_blank">Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via In-Context Learning</a></em> is accepted by Interspeech 2025. Congrats to Junchuan and Xintong!</div></li>
                
                <li><div class="indent2"><b>[2025.02]</b> New paper <em><a href="archive/pdf/2025/2025_on_calibration.pdf" target="_blank">On Calibration of LLM-based Guard Models for Reliable Content Moderation</a></em> is accepted by ICLR 2025. Congrats to Hongfu and Xiangming!</div></li>

                <li><div class="indent2"><b>[2025.02]</b> New paper <em><a href="archive/pdf/2025/2025_when_attention.pdf" target="_blank">When Attention Sink Emerges in Language Models: An Empirical View</a></em> is accepted by ICLR 2025. Congrats to Xiangming!</div></li>
                
                <li><div class="indent2"><b>[2025.02]</b> New paper <em><a href="archive/pdf/2025/2025_on_memorization.pdf" target="_blank">On Memorization in Diffusion Models</a></em> is accepted to TMLR. Congrats to Xiangming!</div></li>
                
                <li><div class="indent2"><b>[2025.02]</b> New paper <em><a href="archive/pdf/2025/2025_Lead_Instrument_Detection_from_Multitrack_Music_final.pdf" target="_blank">Lead Instrument Detection from Multitrack Music</a></em> is accepted by ICASSP 2025. Congrats to Longshen!</div></li>
                
                <li><div class="indent2"><b>[2025.02]</b> New paper <em><a href="archive/pdf/2025/2025_SPSinger.pdf" target="_blank">SPSinger: Multi-Singer Singing Voice Synthesis with Short Reference Prompt</a></em> is accepted by ICASSP 2025. Congrats to Junchuan!</div></li>
                
                <li><div class="indent2"><b>[2025.02]</b> Our lab member Jiaen Sun received the <b><em>REx Fellowship Award</em></b> to conduct her undergraduate research project "<em>Development of language-learning web application to support Human-Computer Interaction research</em>" in our lab. Congratulations</div></li>

                <li><div class="indent2"><b>[2025.02]</b> Our lab members Qihao Liang, JunchuanZhao, and Wei Zeng received the <b><em>SoC's Teaching Fellowships</em></b> in recognition of their outstanding teaching performance as TAs. Congratulations!</div></li>

                <li><div class="indent2"><b>[2025.01]</b> Our lab member Hongfu Liu earns <b><em>SoC Research Achievement Award</em></b>. Congrats to Hongfu!</div></li>

                <li><div class="indent2"><b>[2024.12]</b> A featured article on our core research theme "Sound and Music Computing for Human Health and Potential" (SMC4HHP) is published by NUS social media. [<a href="https://www.comp.nus.edu.sg/features/2024-transforming-stroke-recovery-with-ai-and-music-therapy-wangye/" target="_blank">Website</a>] [<a href="https://www.instagram.com/p/DC3eZsTvfYd/?utm_source=ig_web_copy_link&igsh=MzRlODBiNWFlZA==" target="_blank">Instagram</a>] [<a href="https://www.facebook.com/share/v/19SyvR2tE7/" target="_blank">Facebook</a>] [<a href="https://www.linkedin.com/feed/update/urn:li:activity:7267444836268417025" target="_blank">LinkedIn</a>]</div></li>

                <li><div class="indent2"><b>[2024.10]</b> Our lab member Xiangming Gu, advised by Prof. Ye Wang at NUS, has been selected as a participant for Global Young Scientists Summit 2025. Congrats!</div></li>

                <li><div class="indent2"><b>[2024.10]</b> Our recent event <em>Sound and Music Computing for Human Health and Potential</em> (SMC4HHP) Seminar & Concert is now available. [<a href="/seminar_concert_2024" target="_blank">event page</a>]</div></li>

                <li><div class="indent2"><b>[2024.09]</b> New paper <em><a href="archive/pdf/2024/2024_structured_arrangement.pdf" target="_blank">Structured Multi-Track Accompaniment Arrangement via Style Prior Modelling</a></em> is accepted by NeurIPS 2024. Congrats to Jingwei!</div></li>
                
                <li><div class="indent2"><b>[2024.09]</b> New paper <em><a href="archive/pdf/2024/2024_KeYric.pdf" target="_blank">KeYric: Unsupervised Keywords Extraction and Expansion from Music for Coherent Lyric Generation</a></em> is accepted by ACM TOMM. Congrats to Stan and Varun!</div></li>
                
                <li><div class="indent2"><b>[2024.09]</b> New paper <em><a href="archive/pdf/2024/2024_DeGCG-Transfer_Attack.pdf" target="_blank">Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models</a></em> is accepted by EMNLP 2024. Congrats to Hongfu!</div></li>

                <li><div class="indent2"><b>[2024.09]</b> New paper <em><a href="archive/pdf/2024/2024_SpeechTTA.pdf" target="_blank">Advancing Test-Time Adaptation in Wild Acoustic Test Settings</a></em> is accepted by EMNLP 2024 as well. Congrats to Hongfu one more time!</div></li>

                <li><div class="indent2"><b>[2024.09]</b> Our lab member Hengguan Huang, who has completed his PhD program advised by Prof. Ye Wang at NUS this year, has been appointed as Assistant Professor at the Department of Public Health, University of Copenhagen. Congrats!</div></li>

                <li><div class="indent2"><b>[2024.08]</b> Our lab member Xiangming earns <b><em>Dean's Graduate Research Excellence Award</em></b>. Congrats!</div></li>
                
                <li><div class="indent2"><b>[2024.08]</b> Our lab memebers Qihao, Wei, and Jingwei earn <b><em>Research Achievement Award</em></b>. Congrats to all!</div></li>

                <li><div class="indent2"><b>[2024.07]</b> Our project "Validating an AI enabled co-creation songwriting system CocoLyricist for post-stroke brain training," in collaboration with NUS Yong Loo Lin School of Medicine, earns <b><em>AI in Medicine Collaborative Grant</em></b>. Congrats!</div></li>

                <li><div class="indent2"><b>[2024.07]</b> Our lab member Hengguan Huang earns <b><em>SoC CS PhD Thesis Award - Honorable Mentions</em></b>. Congrats!</div></li>


                <li><div class="indent2"><b>[2024.06]</b> We are seeking RAs and RFs on the topic of AI supported language learning. <a href="opportunities_AI_supported_language_Learning" target="_blank"><em>Job description here</em></a>.</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_Interspeech_2024__Mandarin_Chinese_MDD.pdf" target="_blank">Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and Diagnosis</a></em> accepted by Interspeech 2024. Congrats to Xintong and Mick!</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_SinTechSVS_IEEETrans.pdf" target="_blank">SinTechSVS: A Singing Technique Controllable Singing Voice Synthesis System</a></em> accepted by TASLP. Congrats to Junchuan and Chetwin!</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_benchmarking_large_language_mo.pdf" target="_blank">Benchmarking Large Language Models on Communicative Medical Coaching: A Dataset and a Novel System</a></em> accepted by Findings of ACL 2024. Congrats to Hongfu!</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_XAI_Lyricist_Human_Centred_AI_.pdf" target="_blank">XAI-Lyricist: Improving the Singability of AI-Generated Lyrics with Prosody Explanations</a></em> accepted by IJCAI 2024. Congrats to Qihao and Stan!</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_Piano_A2S_camera_ready.pdf" target="_blank">End-to-End Real-World Polyphonic Piano Audio-to-Score Transcription with Hierarchical Decoding</a></em> accepted by IJCAI 2024. Congrats to Wei!</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_symbolic_music_TMM.pdf" target="_blank">Symbolic Music Generation from Graph-Learning-based Preference Modeling and Textual Queries</a></em> accepted by IEEE TMM. Congrats to Stan!</div></li>

                <li><div class="indent2"><b>[2024.05]</b> New paper <em><a href="archive/pdf/2024/2024_agent_smith.pdf" target="_blank">Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast</a></em> accepted ICML 2024. Congrats to Xiangming!</div></li>

                <li><div class="indent2"><b>[2024.01]</b> New paper <em><a href="archive/pdf/2024/2024_MMSinging_revision_final.pdf" target="_blank">"Automatic Lyric Transcription and Automatic Music Transcription from Multimodal Singing"</a></em> accepted by ACM TOMM. Congrats to Xiangming, Longshen, Wei, Jianan, and Nicholas!</div></li>

                <li><div class="indent2"><b>[2024.02]</b> <b><em>SLIONS-Kids</em></b> is an AI-empowered web application for learning Mandarin Chinese pronunciation developed by NUS Sound and Music Computing Lab. See <a href="video_page#SLIONS_KIDS-trailer" target="_blank">this trailer video</a> for more information about the app.</div></li>
                
                <li><div class="indent2"><b>[2024.01]</b> Prof. Ye Wang receives <b><em>Faculty Teaching Excellence Award</em></b> for AY2023-2024 from NUS School of Computing. Congrats!</div></li>

                <li><div class="indent2"><b>[2024.01]</b> New paper <em><a href="archive/pdf/2024/2024_Drawlody__IEEE_TMM_Finalised.pdf" target="_blank">"Drawlody: Sketch-Based Melody Creation with Enhanced Usability and Interpretability"</a></em> accepted by IEEE Transactions on Multimedia (TMM). Congrats to Qihao!</div></li>

                <li><div class="indent2"><b>[2023.12]</b> Our lab member Hengguan Huang has successfully defended his PhD Thesis entitled <em>"Brain-informed Artificial Intelligence: Random Graphs, Dynamical Systems and Beyond"</em>. Congrats!</div></li>

                <li><div class="indent2"><b>[2023.12]</b> Our lab member Junchuan Zhao has successfully defended his MComp Thesis entitled <em>"Singing Voice Synthesis with Singing Technique Control"</em>. Congrats! Junchuan will start his PhD program at NUS since Spring 2024.</div></li>

                <li><div class="indent2"><b>[2023.12]</b> Our lab member Yuchen Wang has successfully defended her MComp Thesis entitled <em>"Symbolic Music Generation from Graph-Learning-Based Preference Modeling and Textual Queries"</em>. Congrats! Yuchen will start her PhD program at NTU since Spring 2024.</div></li>

                <li><div class="indent2"><b>[2023.11]</b> <em>Sound and Music Computing for Human Health and Potential</em> (SMC4HHP) Themed Concert <a href="/concert_2023" target="_blank">video recordings</a> are now available.</div></li>

                <li><div class="indent2"><b>[2023.10]</b> New paper <em><a href="archive/pdf/2023/2023_AICL_camera_ready.pdf" target="_blank">"Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning"</a></em> accepted by Findings of EMNLP 2023. Congrats to Hongfu!</div></li>

                <li><div class="indent2"><b>[2023.09]</b> New paper <em><a href="archive/pdf/2023/2023_TASLP_PMD_CameraReady.pdf" target="_blank">"Disentangled Adversarial Domain Adaptation for Phonation Mode Detection in Singing and Speech"</a></em> accepted as a regular paper <br>by IEEE/ACM TASLP. Congrats to Yixin, Wei, and Xiangming!</div></li>

                <li><div class="indent2"><b>[2023.07]</b> New paper <em><a href="archive/pdf/2023/2023_ACM_MM2023_Fairness_Singing_camera_ready.pdf" target="_blank">"Elucidate Gender Fairness in Singing Voice Transcription"</a></em> accepted by ACM MM 2023. Congrats to Xiangming and Wei!</div></li>

                <li><div class="indent2"><b>[2023.05]</b> New paper <em><a href="archive/pdf/2023/2023_Interspeech_zero_shot_speech_assessment.pdf" target="_blank">"Zero-Shot Automatic Pronunciation Assessment"</a></em> accepted by Interspeech 2023. Congrats to Hongfu and Mick!</div></li>

                <li><div class="indent2"><b>[2023.05]</b> New paper <em><a href="archive/pdf/2023/2023_ACL_Lyric_Translation.pdf" target="_blank">"Songs Across Borders: Singable and Controllable Neural Lyric Translation"</a></em> accepted by ACL 2023. Congrats to Longshen and Stan!</div></li>

                <li><div class="indent2"><b>[2023.04]</b> New paper <em><a href="archive/pdf/2023/2023_IJCAI_music_rearrangement.pdf" target="_blank">"Q&A: Query-Based Representation Learning for Multi-Track Symbolic Music re-Arrangement"</a></em> accepted by IJCAI 2023. Congrats to Jingwei!</div></li>

                <li><div class="indent2"><b>[2023.02]</b> New paper <em><a href="archive/pdf/2023/2023_ICASSP_phonation_mode.pdf" target="_blank">"Phonation Mode Detection in Singing: a Singer Adapted Model"</a></em> accepted by ICASSP 2023. Congrats to Yixin!</div></li>

                <li><div class="indent2"><b>[2023.01]</b> Our lab member Stan Xichu Ma has successfully defended his PhD Thesis entitled <a href="https://scholarbank.nus.edu.sg/handle/10635/237661" target="_blank"><em>"Selected Advances in Music Computing for Human Health and Potential"</em></a>. Congrats! Dr. Ma has started as a postdoc research fellow in our lab.</div></li>

                <li><div class="indent2"><b>[2023.01]</b> New paper <a href="https://www.tandfonline.com/doi/full/10.1080/09298215.2023.2166848" target="_blank"><em>"Personalized Popular Music Generation Using Imitation and Structure"</em></a> accepted by Journal of New Music Research. Congrats to Stan!</div></li>

                <li><div class="indent2"><b>[2023.01]</b> Four of our PhD students (Hengguan, Stan, Xiangming, and Longshen) wins <b><em>SoC Research Achievement Award</em></b>. Congrats to all!</div></li>

                <li><div class="indent2"><b>[2022.12]</b> Our lab member Wei Wei has successfully defended his PhD Thesis entitled <a href="https://scholarbank.nus.edu.sg/handle/10635/236780" target="_blank"><em>"Acoustic Event Recognition: from Supervised Learning to Unsupervised Learning"</em></a>. Congrats to Dr. Wei!</div></li>

                <li><div class="indent2"><b>[2022.12]</b> New paper <a href="archive/pdf/2022/2022_TMLR_camera_ready.pdf" target="_blank"><em>"Unsupervised Mismatch Localization in Cross-Modal Sequential Data with Application to Mispronunciations Localization"</em></a> accepted by TMLR. Congrats to Wei, Hengguan, and Xiangming!</div></li>

                <li><div class="indent2"><b>[2022.11]</b> Our paper <a href="archive/pdf/2022/2022_ACM_MM_MM-ALT.pdf" target="_blank"><em>"MM-ALT: A Multimodal Automatic Lyric Transcription System"</em></a> wins the <b><em>Top Paper Award</em></b> of ACM Multimedia 2022 (MM'22) conference. Congrats to Xiangming, Longshen, and Danielle! For dataset, code, and demo of this paper, please visit our <a href="https://n20em.github.io/" target="_blank">demo page</a>.</div></li>

                <li><div class="indent2"><b>[2022.11]</b> We are seeking two postdoc research fellows in automatic lyrics generation and automatic singing voice/speech evaluation. <a href="postdoct_job_description_2022" target="_blank"><em>Job description here</em></a>.</div></li>

                <li><div class="indent2"><b>[2022.11]</b> <em>Sound and Music Computing for Human Health and Potential</em> (SMC4HHP) Seminar & Concert <a href="/seminar_concert_2022" target="_blank">video recordings</a> are now available.</div></li>

                <li><div class="indent2"><b>[2022.09]</b> New paper <a href="archive/pdf/2022/2022_ECBNN_full.pdf" target="_blank"><em>"Extrapolative Continuous-time Bayesian Neural Network for Predictive Streaming Domain Adaptation"</em></a> accepted by NeurIPS 2022. Congrats to Hengguan, Xiangming, and Hongfu! <a href="https://recorder-v3.slideslive.com/?share=76177&s=cd597422-3109-42f3-9072-dfef5c351a4d" target="_blank">Presentation video</a> is now available.</div></li>

                <li><div class="indent2"><b>[2022.09]</b> Our Lab member Xiao Liu has defended his MComp thesis titled <em>"Robust Melody Track Identification in Symbolic Music"</em>. Congrats to Xiao!</div></li>

                <li><div class="indent2"><b>[2022.08]</b> New paper <a href="archive/pdf/2022/2022_ALT_ISMIR_2022_Camera_ready 8.23.pdf" target="_blank"><em>"Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription"</em></a> accepted by ISMIR 2022. Congrates to Longshen and Xiangming!</div></li>

                <li><div class="indent2"><b>[2022.08]</b> New paper <a href="archive/pdf/2022/2022_Robust_Melody_Track_Identification_in_Symbolic_Music_Camera Ready.pdf" target="_blank"><em>"Robust Melody Track Identification in Symbolic Music"</em></a> accepted by ISMIR 2022. Congrates to Xichu, Xiao, and Bowen!</div></li>

                <li><div class="indent2"><b>[2022.08]</b> New paper <a href="archive/pdf/2022/2022_Beat Transformer.pdf" target="_blank"><em>"Beat Transformer: Demixed Beat and Downbeat Tracking with Dilated Self-Attention"</em></a> accepted by ISMIR 2022. Congrates to Jingwei!</div></li>

                <li><div class="indent2"><b>[2022.08]</b> New paper <a href="archive/pdf/2022/2022_Adversarial VAE.pdf" target="_blank"><em>"Domain Adversarial Traning on C-VAE for Controllable Music Generation"</em></a> accepted by ISMIR 2022. Congrates to Jingwei!</div></li>

                <li><div class="indent2"><b>[2022.07]</b> New paper <a href="archive/pdf/2022/2022_ACM_MM_User_Preference_Modeling.pdf" target="_blank"><em>"Content based User Preference Modeling in Music Generation"</em></a> accepted by MM'22. Congrats to Xichu and Yuchen!</div></li>

                <li><div class="indent2"><b>[2022.07]</b> New paper <a href="archive/pdf/2022/2022_ACM_MM_MM-ALT.pdf" target="_blank"><em>"MM-ALT: A Multimodal Automatic Lyric Transcription System"</em></a> accepted by MM'22. Congrats to Xiangming, Longshen, and Danielle!</div></li>

                <li><div class="indent2"><b>[2022.06]</b> Our member Yuchen Wang won <em><b>Outstanding Computing Project Prize</b></em> from NUS School of Computing. Congrats to Yuchen! See <a href="https://news.nus.edu.sg/finding-their-calling-in-computing/" target="_blank">NUS news</a>!</div></li>

                <li><div class="indent2"><b>[2022.01]</b> New paper <a href="archive/pdf/2022/2022_ICASSP_APT.pdf" target="_blank"><em>"Exploring Transformer's Potential on Automatic Piano Transcription"</em></a> accepted by ICASSP 2022. Congrats to Longshen!</div></li>

                <li><div class="indent2"><b>[2022.01]</b> Our lab member Hengguan Huang won <em><b>Dean's Graduate Research Excellence Award</b></em> from NUS School of Computing. Congrats to Hengguan!</div></li>

                <li><div class="indent2"><b>[2022.01]</b> Our lab member Xichu (Stan) Ma won <em><b>Research Achievement Award</b></em> from NUS School of Computing. Congrats to Stan!</div></li>

                <li><div class="indent2"><b>[2021.11]</b> Prof. Ye Wang delivered a virtual talk entitled <em>"Neuro-inspired SMC for Bilingualism and Human Potential"</em> at Standford University. <a href="video_page#APSIPA" target="_blank">Video recording</a> is now available.</div></li>

                <li><div class="indent2"><b>[2021.11]</b> Prof. Ye Wang hosted a panel discussion on the topic of <em>"MIR for Human Health and Potential"</em> at ISMIR 2021. <a href="video_page#ISMIR21Panel" target="_blank">Video recording</a> is now available.</div></li>

                <li><div class="indent2"><b>[2021.08]</b> Prof. Ye Wang delivered a keynote speaking on <em>"Music and Wearable Computing for Health and Learning"</em> at Computing Research Week of NUS. <a href="video_page#Keynote202108" target="_blank">Video recording</a> is now available.</div></li>
                
                
                <p></p>
            </ul>
        </div>
            
        </div>

    </div>
</section>





