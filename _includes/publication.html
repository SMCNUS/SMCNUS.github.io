<section class="bg-wight small-padding" id="Publication">
    <div class="container">
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">Selected Publication</h2>
                <hr class="primary">
            </div>
        </div>

    <div class="row">
        <div class="text-lg-start">
        <p class="text-center">[<a href="full_publication_list" style="color:#031d83;"  target="_blank"><em>see FULL publication list</em></a>]</p></div>
    </div>

    <div class="row">
        <div class="text-lg-start">
        <h2 class="section-heading text-uppercase">2025</h2></div> 
    </div>
    <div class="row">
        <ul>

            <li><p class="text-align">L. Ou, J. Zhao, Z. Wang, G. Xia, Q. Liang, T. Hopkins, and Y. Wang, “<a href="archive/pdf/2025/2025_automatic_arrangement_smcl.pdf" target="_blank">Unifying Symbolic Music Arrangement: Track-Aware Reconstruction and Structured Tokenization</a>,” in <i>Proceedings of the 39th Annual Conference on Neural Information Processing Systems (<b>NeurIPS 2025</b>).</i> 2025.</p></li>

            <li><p><p class="text-align">Q. Liang, X. Ma, T. Hopkins, and Y. Wang, “<a href="archive/pdf/2025/2025_LivePoem (IJCAI25 HAI).pdf" target="_blank">LivePoem: Improving the Learning Experience of Classical Chinese Poetry with AI-Generated Musical Storyboards</a>,” in <i>Proceedings of the Thirty-Fourth International Joint Conference on Artificial Intelligence (<b>IJCAI 2025</b>).</i> ijcai.org, 2025.
            [<a href="https://www.youtube.com/shorts/wXI0ITGkm04" target="_blank" style="color:#031d83;">Demo 1 (reciting)</a>]
            [<a href="https://www.youtube.com/shorts/COKSq3fguTA" target="_blank" style="color:#031d83;">Demo 1 (singing)</a>]
            [<a href="https://www.youtube.com/shorts/5aG1sn9X01s" target="_blank" style="color:#031d83;">Demo 2 (reciting)</a>]
            [<a href="https://www.youtube.com/shorts/ZaGJ4Ymh8ss" target="_blank" style="color:#031d83;">Demo 2 (singing)</a>]
            </p></li>

            <li><p class="text-align">J. Zhao, X. Wang, and Y. Wang, “<a href="archive/pdf/2025/2025_Interspeech_464.pdf" target="_blank">Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via In-Context Learning</a>,” in <i>Proceedings of the 26th Annual Conference of the International Speech Communication Association (<b>Interspeech 2025</b>).</i> ISCA, 2025s.</p></li>


            <li><p class="text-align">H. Liu, H. Huang, H. Wang, X. Gu, and Y. Wang, “<a href="archive/pdf/2025/2025_on_calibration.pdf" target="_blank"> On Calibration of LLM-based Guard Models for Reliable Content Moderation</a>,” in <em>Proceedings of the 13th International Conference on Learning Representations (<b>ICLR 2025</b>)</em>. OpenReview.net, 2025.</p></li>

            <li><p class="text-align">X. Gu, T. Pang, C. Du, Q. Liu, F. Zhang, C. Du, Y. Wang and M. Lin, “<a href="archive/pdf/2025/2025_when_attention.pdf" target="_blank">When Attention Sink Emerges in Language Models: An Empirical View</a>,” in <em>Proceedings of the 13th International Conference on Learning Representations (<b>ICLR 2025</b>)</em>. OpenReview.net, 2025.</p></li>
            
            <li><p class="text-align">X. Gu, C. Du, T. Pang, C. Li, M. Lin, and Y. Wang, “<a href="archive/pdf/2025/2025_on_memorization.pdf" target="_blank"> On Memorization in Diffusion Models</a>,” <em> Trans. Mach. Learn. Res. (<b>TMLR</b>) </em>, vol. 2025.
        
            <li><p class="text-align">L. Ou, Y. Takahashi, and Y. Wang, “<a href="archive/pdf/2025/2025_Lead_Instrument_Detection_from_Multitrack_Music_final.pdf" target="_blank"> Lead Instrument Detection from Multitrack Music </a>,” in <i>Proceedings of the 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP 2025</b>).</i> IEEE, 2025.</p></li>
        
            <li><p class="text-align">J. Zhao, C. Low, and Y. Wang, “<a href="archive/pdf/2025/2025_SPSinger.pdf" target="_blank"> SPSinger: Multi-Singer Singing Voice Synthesis with Short Reference Prompt</a>,” in <i>Proceedings of the 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP 2025</b>).</i> IEEE, 2025.</p></li>
        
        </ul>
    </div>

    <div class="row">
        <div class="text-lg-start">
        <h2 class="section-heading text-uppercase">2024</h2></div> 
    </div>
    <div class="row">
        <ul>
            <li><p class="text-align">J. Zhao, G. Xia, Z. Wang, and Y. Wang, “<a href="archive/pdf/2024/2024_structured_arrangement.pdf" target="_blank">Structured Multi-Track Accompaniment Arrangement via Style Prior Modelling</a>,” in <em>Proceedings of the 38th Annual Conference on Neural Information Processing Systems (<b>NeurIPS 2024</b>)</em>.</i> 2024.
                [<a href="https://zhaojw1998.github.io/structured-arrangement/" target="_blank" style="color:#031d83;">demo</a>] 
                [<a href="https://github.com/zhaojw1998/Structured-Arrangement-Code" target="_blank" style="color:#031d83;">code</a>] 
                </p></li> 

            <li><p class="text-align">H. Liu, H. Huang, and Y. Wang, “<a href="archive/pdf/2024/2024_SpeechTTA.pdf" target="_blank">Advancing Test-Time Adaptation in Wild Acoustic Test Settings</a>,” in <em>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (<b>EMNLP 2024</b>)</em>. Association for Computational Linguistics, 2024, pp. 7138-7155.</p></li>

            <li><p class="text-align">X. Ma, V. Sharma, M. Y. Kan, W. S. Lee, and Y. Wang, “<a href="archive/pdf/2024/2024_KeYric.pdf" target="_blank">KeYric: Unsupervised Keywords Extraction and Expansion from Music for Coherent Lyric Generation</a>,” <i>ACM Trans. Multim. Comput. Commun. Appl. (<b>TOMM</b>)</i>, vol. 21, No. 1, pp. 1-28, 2024. </p></li>

            <li><p class="text-align">X. Wang, M. Shi, and Y. Wang, “<a href="archive/pdf/2024/2024_Interspeech_2024__Mandarin_Chinese_MDD.pdf" target="_blank">Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and Diagnosis</a>,” in <i>Proceedings of the 25th Annual Conference of the International Speech Communication Association (<b>Interspeech 2024</b>).</i> ISCA, 2024, pp. 292-296.</p></li>

            <li><p class="text-align">J. Zhao, L. Q. Chetwin, and Y. Wang, “<a href="archive/pdf/2024/2024_SinTechSVS_IEEETrans.pdf" target="_blank">SinTechSVS: A Singing Technique Controllable Singing Voice Synthesis System</a>,” <i>IEEE ACM Trans. Audio Speech Lang. Process. (<b>TASLP</b>),</i> vol. 32, pp. 2641–2653, 2024. </p></li>

            <li><p><p class="text-align">W. Zeng, X. He, and Y. Wang, “<a href="archive/pdf/2024/2024_Piano_A2S_camera_ready.pdf" target="_blank">End-to-End Real-World Polyphonic Piano Audio-to-Score Transcription with Hierarchical Decoding</a>,” in <i>Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (<b>IJCAI 2024</b>).</i> ijcai.org, 2024, pp. 7788-7795.</p></li>

            <li><p class="text-align">X. Gu, L. Ou, W. Zeng, J. Zhang, N. Wong, and Y. Wang, “<a href="archive/pdf/2024/2024_MMSinging_revision_final.pdf" target="_blank">Automatic Lyric Transcription and Automatic Music Transcription from Multimodal Singing</a>,” <i>ACM Trans. Multim. Comput. Commun. Appl. (<b>TOMM</b>),</i> vol. 20, No. 7, pp. 1551-6857, 2024. </p></li>

            <li><p class="text-align">Q. Liang and Y. Wang, “<a href="archive/pdf/2024/2024_Drawlody__IEEE_TMM_Finalised.pdf" target="_blank">Drawlody: Sketch-Based Melody Creation with Enhanced Usability and Interpretability</a>,” <i>IEEE Trans. Multim. (<b>TMM</b>),</i> vol. 26, pp. 7074-7088, 2024.</p></li>
        </ul>
    </div>
    

    <div class="row">
        <div class="text-lg-start">
        <p class="text-center">[<a href="full_publication_list" style="color:#031d83;"  target="_blank"><em>see FULL publication list</em></a>]</p></div>
    </div>

    </div>
















    </div>
</section>
